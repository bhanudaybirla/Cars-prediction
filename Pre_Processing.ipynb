{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJnaMkl0k-1h",
        "colab_type": "text"
      },
      "source": [
        "# Cars' Year Make Model Prediction using CNN\n",
        "I have divided the complete modeling activity into 3 parts and created one notebook for each part.\n",
        "\n",
        "\n",
        "1.   **Pre-processing**\n",
        "2.   **Training (Transfer Learning) and Validation**\n",
        "3.   **Prediction**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAeCQ_AHbyFn",
        "colab_type": "text"
      },
      "source": [
        "# Step 1. Pre-processing of image dataset\n",
        "The steps involved in preparing image dataset are below:\n",
        "\n",
        "\n",
        "1.   Download the dataset and unzip it into google colab workspace\n",
        "2.   Create training, validation sets from initial training set and organize according to class label\n",
        "3. Put test dataset in test folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pkhu7QkbnIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "b070071f-48a9-4d1c-ce7e-25076d9fa96e"
      },
      "source": [
        "!pip install console_progressbar"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting console_progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/70/dd/5103450098d904eb276c188fe500e1d757cb82ffdc02c02aa4de8faaccea/console_progressbar-1.1.1.tar.gz\n",
            "Building wheels for collected packages: console-progressbar\n",
            "  Building wheel for console-progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/75/2c/d26751f4f3d2cd72d58d10313113691e87995630c89aab231b\n",
            "Successfully built console-progressbar\n",
            "Installing collected packages: console-progressbar\n",
            "Successfully installed console-progressbar-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS2bdVaLeyq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import tarfile\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2 as cv\n",
        "import shutil\n",
        "import random\n",
        "from console_progressbar import ProgressBar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4GVxdSt4UX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34_FMnTbiQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount(path+'/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU19DLmndYEQ",
        "colab_type": "text"
      },
      "source": [
        "Downloading and unzipping the dataset from the given website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2QBrOOkgP1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "!wget http://imagenet.stanford.edu/internal/car196/cars_test.tgz\n",
        "!wget https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz -P\n",
        "!unzip -qq /content/cars_train.tgz\n",
        "!unzip -qq /content/cars_test.tgz\n",
        "!unzip -qq /content/car_devkit.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_3eyPf9gbvb",
        "colab_type": "text"
      },
      "source": [
        "Now, created some functions to get bounding boxes of cars and extracted that box with a margin of 16 pixels out of full images. The training datset is distributed into two sets i.e. train and valid sets with 80:20 ratio. The folder structure for train and valid will look like:\n",
        "\n",
        "```\n",
        "train\n",
        "        /Class 1\n",
        "                /00003.jpg\n",
        "                /00234.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "        /Class 2\n",
        "                /00043.jpg\n",
        "                /00004.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "       /Class 196\n",
        "                /03003.jpg\n",
        "                /00034.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "valid\n",
        "        /Class 1\n",
        "                /00003.jpg\n",
        "                /00234.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "        /Class 2\n",
        "                /00043.jpg\n",
        "                /00004.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "       /Class 196\n",
        "                /03003.jpg\n",
        "                /00034.jpg\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "test\n",
        "          /00012.jpg\n",
        "          /00239.jpg\n",
        "          .\n",
        "          .\n",
        "          .\n",
        "```\n",
        "\n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDRl6kTGdUag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensure_folder(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "\n",
        "def save_train_data(fnames, labels, bboxes):\n",
        "    src_folder = path+'/cars_train'\n",
        "    num_samples = len(fnames)\n",
        "\n",
        "    train_split = 0.8\n",
        "    num_train = int(round(num_samples * train_split))\n",
        "    train_indexes = random.sample(range(num_samples), num_train)\n",
        "\n",
        "    pb = ProgressBar(total=100, prefix='Save train data', suffix='', decimals=3, length=50, fill='=')\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        fname = fnames[i]\n",
        "        label = labels[i]\n",
        "        (x1, y1, x2, y2) = bboxes[i]\n",
        "\n",
        "        src_path = os.path.join(src_folder, fname)\n",
        "        src_image = cv.imread(src_path)\n",
        "        height, width = src_image.shape[:2]\n",
        "        # margins of 16 pixels\n",
        "        margin = 16\n",
        "        x1 = max(0, x1 - margin)\n",
        "        y1 = max(0, y1 - margin)\n",
        "        x2 = min(x2 + margin, width)\n",
        "        y2 = min(y2 + margin, height)\n",
        "        # print(\"{} -> {}\".format(fname, label))\n",
        "        pb.print_progress_bar((i + 1) * 100 / num_samples)\n",
        "\n",
        "        if i in train_indexes:\n",
        "            dst_folder = path+'/train'\n",
        "        else:\n",
        "            dst_folder = path+'/valid'\n",
        "\n",
        "        dst_path = os.path.join(dst_folder, label)\n",
        "        if not os.path.exists(dst_path):\n",
        "            os.makedirs(dst_path)\n",
        "        dst_path = os.path.join(dst_path, fname)\n",
        "\n",
        "        crop_image = src_image[y1:y2, x1:x2]\n",
        "        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n",
        "        cv.imwrite(dst_path, dst_img)\n",
        "\n",
        "\n",
        "def save_test_data(fnames, bboxes):\n",
        "    src_folder = path+'/cars_test'\n",
        "    dst_folder = path+'/test'\n",
        "    num_samples = len(fnames)\n",
        "\n",
        "    pb = ProgressBar(total=100, prefix='Save test data', suffix='', decimals=3, length=50, fill='=')\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        fname = fnames[i]\n",
        "        (x1, y1, x2, y2) = bboxes[i]\n",
        "        src_path = os.path.join(src_folder, fname)\n",
        "        src_image = cv.imread(src_path)\n",
        "        height, width = src_image.shape[:2]\n",
        "        # margins of 16 pixels\n",
        "        margin = 16\n",
        "        x1 = max(0, x1 - margin)\n",
        "        y1 = max(0, y1 - margin)\n",
        "        x2 = min(x2 + margin, width)\n",
        "        y2 = min(y2 + margin, height)\n",
        "        # print(fname)\n",
        "        pb.print_progress_bar((i + 1) * 100 / num_samples)\n",
        "\n",
        "        dst_path = os.path.join(dst_folder, fname)\n",
        "        crop_image = src_image[y1:y2, x1:x2]\n",
        "        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n",
        "        cv.imwrite(dst_path, dst_img)\n",
        "\n",
        "\n",
        "def process_train_data():\n",
        "    print(\"Processing train data...\")\n",
        "    cars_annos = scipy.io.loadmat(path+'/devkit/cars_train_annos')\n",
        "    annotations = cars_annos['annotations']\n",
        "    annotations = np.transpose(annotations)\n",
        "\n",
        "    fnames = []\n",
        "    class_ids = []\n",
        "    bboxes = []\n",
        "    labels = []\n",
        "\n",
        "    for annotation in annotations:\n",
        "        bbox_x1 = annotation[0][0][0][0]\n",
        "        bbox_y1 = annotation[0][1][0][0]\n",
        "        bbox_x2 = annotation[0][2][0][0]\n",
        "        bbox_y2 = annotation[0][3][0][0]\n",
        "        class_id = annotation[0][4][0][0]\n",
        "        labels.append('%04d' % (class_id,))\n",
        "        fname = annotation[0][5][0]\n",
        "        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
        "        class_ids.append(class_id)\n",
        "        fnames.append(fname)\n",
        "\n",
        "    labels_count = np.unique(class_ids).shape[0]\n",
        "    print(np.unique(class_ids))\n",
        "    print('The number of different cars is %d' % labels_count)\n",
        "\n",
        "    save_train_data(fnames, labels, bboxes)\n",
        "\n",
        "\n",
        "def process_test_data():\n",
        "    print(\"Processing test data...\")\n",
        "    cars_annos = scipy.io.loadmat(path+'/devkit/cars_test_annos')\n",
        "    annotations = cars_annos['annotations']\n",
        "    annotations = np.transpose(annotations)\n",
        "\n",
        "    fnames = []\n",
        "    bboxes = []\n",
        "\n",
        "    for annotation in annotations:\n",
        "        bbox_x1 = annotation[0][0][0][0]\n",
        "        bbox_y1 = annotation[0][1][0][0]\n",
        "        bbox_x2 = annotation[0][2][0][0]\n",
        "        bbox_y2 = annotation[0][3][0][0]\n",
        "        fname = annotation[0][4][0]\n",
        "        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
        "        fnames.append(fname)\n",
        "\n",
        "    save_test_data(fnames, bboxes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zlc7wM1gbGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 224, 224\n",
        "cars_meta = scipy.io.loadmat(path+'/devkit/cars_meta')\n",
        "class_names = cars_meta['class_names']  # shape=(1, 196)\n",
        "class_names = np.transpose(class_names)\n",
        "print('class_names.shape: ' + str(class_names.shape))\n",
        "print('Sample class_name: [{}]'.format(class_names[8][0][0]))\n",
        "\n",
        "ensure_folder(path+'/train')\n",
        "ensure_folder(path+'/valid')\n",
        "ensure_folder(path+'/test')\n",
        "\n",
        "process_train_data()\n",
        "process_test_data()\n",
        "\n",
        "# clean up\n",
        "shutil.rmtree(path+'/cars_train')\n",
        "shutil.rmtree(path+'/cars_test')\n",
        "# shutil.rmtree('devkit')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}